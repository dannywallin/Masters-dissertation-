# Masters-dissertation-
Masters dissertation

**Human Musicians versus MIDI** 
**For Aglaia Foteinou 
**7MU011 Audio Technology** 
**2018/2019**

**Abstract:**

Across the ages there have been musicians who were so talented, they could play perfectly at a live gig because there was no option of computer enhancement. As modern technology has developed humans have been programming computers to recreate the sounds of a human musician, such as; a guitarist, drummer or even vocalist. Computer programmes now are so sophisticated that music can be made by people in the comfort of their own home and by more people than ever before.
The 20th Century has given rise to new opportunities within the music industry; consequently, this dissertation seeks to ascertain whether there is now a higher standard of music production because of the capacity to polish a recording or whether the music is becoming too polished and therefore, creates a standard which real musicians may never to be able to reach. As a result, a small group of musicians were tasked with learning two songs, in the style of 1) rock and 2) pop. The songs were chosen to highlight simplicity as well as difficulty. Sections were taken to compare and contrast against a computer generated track of the same recording. The results highlight how there are subtle differences between every take of each recording due to musicians improvising. This is especially so when a metronome is not used. Overall there are distinct differences between what is technically possible with a real life musician and what is technically possible with a computer programme. Ultimately, real life musicians can give more depth and communicate emotion far better than a computer generated or computer enhanced song. However, the computer programme can make adjustments for musicians’ errors and can be programmed to play drum beats which would be impossible for a human musician. Computers are simply getting better as they evolve and are very unlikely to be removed from the world of music; therefore the boundaries of what constitutes music are forever being challenged.


**Introduction/Literature Review:**

The aim of this dissertation was to ask three musicians to learn two pieces of music, originally composed on a computer, in the form of 1) Rock and 2) Pop music. These songs were then taken into a recording studio and were recreated using live musicians/instruments. The instruments used were; Electric guitar, Bass guitar and Drums. The musicians were tasked with playing both songs as a live band, to a metronome and without a metronome, to compare and contrast with the computer generated songs. Additionally, they also played the songs as a full band and individually with and without a metronome. These tests were created to examine the differences in musical composition between the music generated with and without a metronome. However before this a literature review was undertaken, to examine the history of live versus computer generated music. 
Computer generated music is relatively new and has only become mainstream since the 1950’s approximately.  This has created opportunities for musicians, as well as disadvantages. According to Williams (1997) the first computer generated musical melody was created by the Commonwealth Scientific and Industrial Research Automatic Computer (CSIR Mark 1) in Australia, in 1950, by Trevor Pearcey and Maston Beard. Live music began in the 17th century but it was not until the 1950’s, when concerts began to attract much larger audiences, facilitated by air travel and pre-war efforts to bring people together (Brenna, 2016). This has led to modern day concerts which now can attract 1000’s of people from across the world (Brenna, 2016). However, there are differences between the concerts available; some people prefer live, classical music whereas mainstream bands tend to record in studios as well as play live. Many musicians will have spent years perfecting their craft (Brenna, 2016); some will be self- taught, others will have taken exams through an officially recognised exam board.
Over the years tools and tricks have been used to create a flawless performance in the studio. In the 1950’s 60’s and 70’s bands would record together, live in a studio, with microphones strategically placed (Woodward, 2013). This meant musicians had to, not only play to a professional standard, they also had to synchronise with each other. The recordings were placed on tape and could not be easily changed. The reason for this is because two instruments could be put through a single, signal channel, in order to record. This meant it was not easy to separate the recordings of the instruments. Consequently, in the days of analogue (pre- digital) recordings had to be manually manipulated. For example, the tape which the musicians had recorded to would have to be cut and glued, to correct a mistake or ensure the recording was played as precisely as possible (Dunkley, 2011). The Digital era has eradicated the need for tape and is now much more efficient for creating a flawless finish. It is now possible and common for musicians to play individually rather than playing as a band altogether in the recording studio (Kagan, 2013). Although what is possible today was within reason, possible previously, it would however, have been incredibly time consuming (White 2010).
However, one of the arguments for digitally enhanced music is that it is reducing the standard required by musicians (Alexander, 2019); although this creates an opportunity for musicians and budding musicians to create music anywhere, with the right equipment, rather than needing to pay for expensive recording studios (Alexander, 2019). The reason for this is because of the invention of the MIDI. MIDI became a huge asset to music around 1983 because it provided a language that analogue systems could not replicate (Young, 2001). A Musical Instrument Digital Interface (MIDI) enables any human being to create music, without ever having picked up an instrument. This is because any instrument can be brought as a sample pack, online and installed into a Digital Audio Workstation (DAW) (White 1999). This is recording software which is installed on a person’s computer. Consequently a non- musician who is adept at using a computer can create music, with no musical ability or musician (Try, 2009).  This has created opportunities for non-musicians to be part of the musical world and record and release music, in exactly the same way as an actual musician (Conant 2014). However, there are disadvantages which are associated with using computer generated music compared to having live musicians record in a studio; these will be discussed in the next section.
     
Communication of emotion:
One common theme is the expression and communication of emotion in music performance.  Sloboda (2010) argues music has the capacity to convey the musician’s emotion through a melody line, timing, dynamic states and the lyrics, in order to tell a story; it is this which connects people with music. Juslin (1997) suggests other features which facilitate expression of emotion to the listener, include; tempo and loudness. All of the above can be used to change a listener’s psychological state (Sloboda, 2010). From a technical perspective, when music is made on a computer, the emotion can be taken away (Patrik, 2006).  However, Wallis, Ingalls, and Campana (2008) created an algorithm on a computer, to play music which corresponded to different human emotions. This opened up a new era in the world of music producing (Sloboda (2010).  Past researchers have discovered that emotions, bought by human playing musicians, could be clearly recognized by an audience containing both musically trained and untrained listeners (Juslin 1997a; Juslin 1997b). A number of things which can affect the final version of a song will be discussed throughout.


**Tempo**

Another key theme and area to discuss is the use of tempo in music which pertains to the speed in which a piece of music is played (Edworthy 2006). When recording in a studio or with computer generated music, the tempo is set, either electronically or by a metronome (Debarnot, 2014) Computer generated music is played to a grid line and thus can create a perfect, continual tempo, in each section. However, a musician is a human being and therefore it is harder for them, to play so precisely, to a grid line compared to a computer (Bartlett 2014).  An example of this is when bands are set to walk onto a stage; their adrenaline makes their internal clocks speed up (Falk, 2014). Additionally, in a studio each band member will play individually; it is common for a drummer to be recorded first as they provide the beat, in which each other member has to adhere to (Falk, 2014). Therefore tempo is a key aspect of recording and producing music. This was one such area which was tested in this project. This enables producers to glue each instrument into the final mix and gives more freedom when deciding on the best recorded takes to use (Bartlett 2014). 
Dynamics
Tempo affects the dynamics in a song; the reason for this is because dynamics relates to how hard or softly an instrument is played (Stuart, 1997). Consequently, dynamics creates variation across different performances. This is something a computer cannot recreate easily and certainly cannot be done, without a music producer changing the velocity hits manually (Hill, 1997). Thiemel (2019) explains dynamics further as volume intensity i.e when notes and sounds are emphasised and/or expressed. Dynamics became an important parameter for music in the 20th Century as they help create a structure and a meaning behind music (Hill, 1997). Dynamics are also being tested in this project because two of the most important musical features that distinguish genres of music, especially rock and pop music are variations in tempo and dynamics (David, 1994).  This is because both are related to the conveyance of human emotion (David, 1994). To give an example when writing MIDI in a computer, the default MIDI velocity level is 120 (this is the speed of each hit). However, it is the producer’s responsibility to manually change this to create a more human feel, i.e so each note played is not played at the same velocity which would make it sound robotic (Muro, 1993). (The two songs composed for this project were all at a velocity of 120 to compare with the musicians in the recording process).  
However, in live performances dynamics are expressed quite differently, compared to a studio recording because the musicians are no longer playing to a metronome; as a result they can naturally be affected by the buzz of the crowd which creates adrenalin surges. This has the capacity to change the way the song is played. This will also be discussed in the primary research findings (Berndt and Hähnel, 2010).
Psychology also impacts on emotion in the recording stage (Wallis, 2008). Practice is an important factor because it leads to a better performance (Lehmann, 2007) . However, over practicing can create boredom and affect the recorded song (Hracs, 2016). 
Furthermore, as musicians become proficient, it is not uncommon for them to want to improvise describes Nachmanovitch (1993) and this can be difficult in a recording studio, when each instrument is recorded separately and to a metronome. In contrast, improvisation is more likely to happen at a live event (Hracs, 2016).


**Timbre**

Wessel (1999) states how the emphasis of timbre has been on harmony. Most acoustical instruments provide accurate control over pitch but provide little possibility of manipulating timbre. Many components in music are interrelated for example; dynamic effects timbre, throughout a performance and creates again a more humanized performance (Lexer, 2012). This is because sounds generated will vary between musicians, for example; how hard a key is played has the capacity to affect the frequencies generated. This is another key area in the primary research which has been investigated and is why the primary instruments were chosen for this project as they are common in all bands; these will be discussed next.


**Drums**

Bresin (2000) explained when musicians read from a musical score, performers deviate in time, sound level and timbre from the written score. This is partly why in classical, live music performances conductors are used to keep everyone in time (Fryden, 1991); whereas with computer generated music, the music is kept in time, perfectly, by playing to a grid line. However, Fryden (1991) argues music written by computer algorithms and programmed by computers often sounds lacklustre; although this can depend on the variation and expressions produced by a human producer. 

The first instrument to be recorded tends to be the drums, in order to set the beat, as discussed previously. There are many variables which can affect the sound quality when recording drums in a studio, these include; the room being used to record; the microphone placement and the musical ability/standard of the drummer (White, 2006). Ideally drums should be recorded in a big room, with good acoustics and a technically capable drummer (White, 2006). However, regardless of how good the room, the acoustics and sound equipment are, if the drummer is poor, the recording is likely to be poor. One way to support a drummer is being able to play to a metronome but it has been argued this constrains the drummers expression (Horning, 2013).

Alternatively, it is possible to buy sample drum packs which have been produced in world class studios, with the best equipment, to be used with a MIDI and recording software Mynett (2016). This facilitates two things; 1) the producer does not need a drummer at all or 2) the drummer does not have to be technically brilliant as the computer/MIDI can be programmed to correct the mistakes or replace large parts of the recording (Pack,2018).Either way the end result will be a polished song . The advantage of using additional drum samples is that it can add depth to the original drum take, especially for rock music which is a heavily, drum oriented genre. Therefore adding a bass drum and snare drum sample helps “punch through” the wall of sound (Mynett, 2016). The disadvantages of using drum samples is that the over use of these can sterilize the natural energy that was originally captured in the drum recording (Mynett , 2016). 
 
**Bass**

Following on from Drums, the bass guitar is also a commonly recorded part of any band. Similarly it is also possible to buy bass guitar pack sample to be used with a MIDI (Pejrolo and DeRosa, 2007). Therefore if a bass guitar player is not good enough for a particular song or plays poorly, the samples can be used instead to by- pass the live musician (Pejrolo and DeRosa,2009). The original take is listened to, to ascertain what notes were being played throughout the song. The producer then programs the notes into the computer, thus a midi bass replaces the original bass and sounds much better. The disadvantage of Bass MIDI is latency which is a time delay between the request and the motion/sound (Killelea,2002); Latency is a problem in the studio when recording and in mixing, due to a build-up of delays in milliseconds from audio signals from the audio interface (Miles,2009); this then effects recordings to the point where it puts musicians out of time (Russtein, 2009).To eradicate this problem, it takes time to detect the lowest note of the chord (known as a fundamental) and within reason correct it (Hoepfinger, 2018). 

**Guitar**

The third instrument to be used in this project is the guitar which is a big factor especially, if the music is very technical. The same applies with this instrument in that guitar MIDI packs can also be brought (Hube,2007).There are a number of disadvantages to using MIDI packs though and this includes how apparent it will be, when the band plays live on stage. Additionally, a MIDI guitar, removes the expression and human aspect of the performer due to it being a computer generated piece. Friberg (2000) explains further conflicts may exist between the general character of the composition and the prescribed emotional quality of its performance. Human performance naturally, speed ups and slows down in sections of the songs. This makes a human performance more realistic whereas sample packs using MIDI, conflicts with a human performance and has the capacity to takes away from the original composition. 

**Methods:**
The purpose of this investigation was to explore the differences between two computer generated songs versus 3 live musicians playing the same songs.

The first stage of this project began by writing two songs using MIDI instruments to create 1) rock and 2) pop song. The two songs had difficult technical aspects to them which included; different tempos, specific drum styles, certain drum fills and difficult guitar and bass sections. These ranged from fast playing to difficult melody lines to perform. These songs were sent to each musician along with the score to help them prepare for the recording studio. They were all briefed with what tests would be expected of them to do.

A number of scenarios were created with the 3 musicians who participated in this project. The specific scenarios were;
1)	The musicians played both songs together in a live setting to a metronome
2)	The musicians were then asked to replay both songs, in a live setting but without the metronome.
3)	The musicians were then tasked to play small sections of the songs individually to a metronome
4)	The individual musicians re-recorded small sections of the songs individually without the metronome

Each recording was then compared and contrasted with a number of key performance indicators, these included;

1)	Communication of emotion
2)	Tempo
3)	Dynamics
4)	Timbre


The study used a mixed methods approach yielding both qualitative and quantitative data for the purpose of analysis. Qualitative data is defined as techniques used to collect research which consists of worded answers, to reflect thoughts, opinions and experiences (Bradley, 2013). Qualitative data was gathered through the use of semi structured interviews (see appendix 1). Questions were asked to capture the musicians’ thoughts, opinions and experiences. The advantages of semi structured interviews are they can collect good, quality data, are cost effective and time efficient for this type of project (Bradley, 2013). They also enable the researcher to ask additional questions, to clarify points being made. However, there are associated disadvantages too, these include pre written questions can be biased and affect the answers, by semi shaping the responses. This can reflect the thinking of the researcher, more so than the participants’ responses. Additionally, they offer the opportunity for the participant to give dishonest answers (Denscombe, 2017). In this study, the musicians were well known to the researcher and thus all chose to take part. This therefore negates many of the disadvantages. The questions were specifically open ended which encourages the musicians to elaborate and explain more fully their ideas (Bradley,2013) .Questionnaires are an alternative way of gathering data, but they were not used for this project as it would not allow the researcher to ask further questions, to clarify sections and this was deemed a distinct disadvantage for this research project (Denscombe,2017).
Additionally, quantitative data was gathered through the audio recordings. Screenshots of waveforms from the recording will be found in the Results and Discussion section. Quantitative data is explained by Bradley (2013) as research which generates answers as numbers and statistics. The audio recordings were used to highlight key areas of how each performance, by a live performer is different compared to how a computer generated song can be created perfectly each time. 
In terms of validity, validity is defined as how valid and reliable a study is (Denzin and Lincoln, 2011). This study is deemed valid because this research can be replicated in another studio following the same guidelines. In addition to validity, it is important research is reliable. Reliability is defined as the degree to which the results of this research are accurate (Punch, 2004). This research aims to be both valid and reliable. however it is a small scale study. One of the biggest limitations will be the fact it only uses 3 musicians and is therefore perhaps not generalizable to all musicians across the globe.

**Ethical Considerations:**

When undertaking research it is essential to adhere to ethical considerations in order not to harm participants (Wolverhampton University Ethics Board, (WLVEB) 2019). Consequently, informed consent was sought from all musicians (see appendix 3,4,5) –All musicians were told what the study was about and thus no deception was involved (Bella, 2003). All musicians were given the option of withdrawing from the study at any point (Punch, 2004). All musicians were assured of anonymity (Bradley, 2010).

**Results & Discussion:** 

The specific scenarios were;
1.	The musicians played both songs together in a live setting to a metronome
2.	The musicians were then asked to replay both songs, in a live setting but without the metronome.
3.	The musicians were then tasked to play small sections of the songs individually to a metronome
4.	The individual musicians re-recorded small sections of the songs individually without the metronome

Each recording was then compared and contrasted with a number of key performance indicators, these included;

5)	Communication of emotion
6)	Tempo
7)	Dynamics
8)	Timbre


**Pop song with the metronome:**

In take one, of the pop song that was recorded, it was well played and in time with the metronome. However, some bars were off the grid whereas other bars were tight to the grid.  The drummer created his own drum fills rather than playing the original drum fills. Furthermore he played hi hats for the timing, at the start (this was not in keeping with the original song); technically he had a metronome for timing. At 0.19 a kick and snare fill were played in take one; however, with the three other takes this fill was not performed. Interestingly, in take one around 0.58 the drummer played a fill on the snare just as the song progressed into the bridge where the dynamics changed and became quieter. This was not in keeping with the original song. This was the only take where the snare only was used for this section. 

![](https://github.com/dannywallin/Masters-dissertation-/blob/master/introduction%20of%20drums%20in%20pop%20song.png)
Figure 1 introduction of the of the drums for the pop song

In take two the drummer used hi hats instead. Unfortunately, the snare is late at 0.18 compared to take three and four where they replicated the original.  Additionally, in the last chorus the drum fill from the bridge is all different from the original song.  Lastly, during 2.16 there were no guitars for a second just bass and drums.
In take three the snare and tom were used for the fill and in take four he used the toms to mark the change; these are different compared to take one where there was no fill just a signal from the hi hat. And again, in take two at 1.40 there was no fill, just an extra bass drum hit. The band played well to the metronome, everything was in time with the original song which shows good musicianship being able to play to a metronome. 
Therefore each take was different due to the drummer improvising even though the musicians were tasked with learning the song, to mimic the computer generated song. This links back to Nachmanovitch’s (1993) point who states it is not uncommon for creative musicians to improvise. This was seen throughout all the recordings.  One consistency was the use of hi hats in the verses, across each take. 
The Bass guitar dynamics throughout the majority of the first take were consistent until around the bridge and final chorus where there was some miss hits. The electric guitar was played at a nice, low level with dynamics, throughout the duration of the song. Thiemel (2019) explains dynamics are an essential component of any song and are controlled by the musicians especially in relation to volume intensity i.e when notes and sounds are emphasised and/or expressed. Despite this, there were five seconds during-1.55 where a small section of chords being played were cutting out, this may be down to the cable or the amplifier Nelson (2010). 
Towards the end of the song the band did not know where to properly end the song. Unfortunately, the band had had only a short time to rehearse the 2 songs.  However, what was apparent is the differences between performances in a studio when recreating a song and what is likely to happen in a live situation. This research highlights with different takes of the same song, using live performers then there will be differences each time (see screenshots below highlighting the differences between the accuracy of takes from the computer generated track compared to the live recording: chorus 1 from take 1&2)

![](https://github.com/dannywallin/Masters-dissertation-/blob/master/figure%202%20difference%20of%20takes%20with%20and%20without%20a%20metronome.png)
Figure 2 Difference between takes with and without the metronome


The drummer and guitarist stated playing with a metronome “felt like I could count the measures of the song more consistently and my playing felt more structured”. However, the guitarist added with the sound of the backing track and live band, he could not always concentrate on the metronome.
In terms of communication of emotion the drummer explained “The pop song was more relaxed… felt like it flowed better from me as a player more. However, I felt underprepared for the rock song and it took more concentration, causing the track to loose it’s human and natural feel.”

**Without metronome**
In every instance of the pop song takes, without a metronome, the band played more slowly and thus slight timing discrepancies were seen throughout, even though  there was a backing track for the band to play to. The timing then affects/ or changes the dynamics of the song. This is supported by (Stuart, 1997) describing how tempo affects the dynamics in a song; the reason for this is because dynamics relates to how hard or softly an instrument is played. To provide examples of this at 0.39, the guitar in take one has similar problems to the previous recordings with the metronome where the chords seem to cut out slightly, something that would be a problem in the computer generated song. During the bridge where the dynamics change, the bass in take three 1.10 adds a note in the bridge section. This is the same during 1.39 whereby the bassist plays a note early; it worked well with the song but is the only time out of all the four takes that it happens. Again, improvisation and subtle changes which deviate from the original song are happening.

![](https://github.com/dannywallin/Masters-dissertation-/blob/master/figure%203%20take%20one%20of%20pop%20song%20without%20metronome.png)
Figure 3 Take one of Pop song without metronome


Without a metronome the drummer stipulated “it was harder keeping my playing completely even, but I had more freedom with the drum fills”. The guitarist “I felt comfortable playing without the metronome but I had to be more aware of the drummer”.


**Rock song with metronome**

The rock song is more technically challenging and thus harder for the band to perfect as well as the original track. Folliwng on from this during some takes, there was times when parts were distracted by small latency, due to the cables and time taking form Pro Tools to the headphones. In the first take the band were each getting used to playing the song, this resulted in the first two takes being short, for example 0.09 in take one the guitar stopped and did not start playing fully until 0.12, after the drums played a fill then the whole band continued playing until they stopped around 0.20 mark. 

![](https://github.com/dannywallin/Masters-dissertation-/blob/master/Figure%204%20Take%20one%20of%20the%20Rock%20song%20which%20the%20band%20stopped%20paying%20after%20a%20short%20time.png)
Figure 4 Take one of the Rock song which the band stopped paying after a short time


In take two the band played longer but still with mistakes throughout. At 0.11 where everyone apart from the drummer should stops but the guitarist failed to stop. The drummer struggled with the speed of the drum fills due to concentrating on the track then having to go straight into a fast fill. The guitarist struggled to play at a consistent level throughout the song.

**Take three**
The bassist appeared to be struggling to play the song as he followed the lead guitarist. This affects timing and the cohesion of the song  (see more in blog)

The Guitar solo was very different from the original take, as he improvised a lot. Hracs (2016) described how when playing live, improvising is very common which happened throughout these recordings in each recording. After the rock song recording was completed, the guitarist explained, “Playing the melody of the rock song was technically/mechanically easy but due to the somewhat chaotic nature of the song, it was a challenge to focus on the backing track whilst playing with the band.”

**Take four**
In take four at 1.17 the guitar and bass stop for 3 seconds before all coming back in (screenshot). Additionally, the drum fill at 1.42 is different compared to take three which showcases that no take can be replicated perfectly, unlike a programmed drum beat. Whilst the band were playing to the track, they still struggled to play well to the metronome as throughout the song they went out of time regularly. The reason maybe the technical level of the track and the short space of time the musicians had to learn it. 

![](https://github.com/dannywallin/Masters-dissertation-/blob/master/Figure%205%20first%20arrow%20when%20electric%20Guitar%20stops%20and%20second%20is%20when%20it%20starts%20playing%20again.png)
Figure 5 first arrow when electric Guitar stops and second is when it starts playing again


Rock song without the metronome

When the rock song was recorded without the metronome the band were more confident with the song which then helped them complete the song in full. However, there were many mistakes throughout the song. To give examples; each solo on every take is similar but very different from the original. At 2.23 (take three) the guitar came in early, despite a drum fill being played. At 2.27 the guitar stops till 0.30 where it starts playing again properly.

Being more confident the song, the band played faster due to the faster nature of the song and genre which links back to how adrenaline effects people once they have nothing to make them play to a certain tempo.

Snare rolls within the rock song are all vary in dynamics compared to the computer created song. Lexer (2012) explains how dynamics affect Timbre throughout a performance and creates again a more humanised performance. The change of dynamics link back to how live performers are not able to play the same 120 velocity hits throughout the song “ Keeping on top of some of the song structures and making dynamics sound human rather than too intentional/planned out and predictable.”


The drummer explained how “The dynamics in the rock song affected my playing because the changes were so sudden, it meant I had to quickly and drastically change my approach to the drum kit, for example playing fills on particular parts of the kit. In the pop song the dynamics were more expected and stronger so when it got to a different section, it became easier to remember that this section was quieter/louder and I could transfer to the light Cymbal work/full kit easier. This also meant that getting across the feelings of the song became easier in the pop track as I could collectively bounce fills and rhythms off the other players. With the rock track, it was much more specific fills leading into sections meaning it was impossible to preempt.”
By comparison the guitarist described how “The pop song was very easy to play with a band. However, the rock song already had a drum part this made the song difficult to play, with both a real and programmed drummer. Once I played with just the backing track by myself I found it much easier.”


After all three instruments were recorded the drummer explained the difference between playing in a group compared to playing individually “I feel playing in a band allows me to bounce ideas off the other musicians whereas playing solo allowed me to focus on my parts more, however there is more pressure playing alone.”

**Conclusion**
Music productions have vastly changed over the past thirty years, for example productions were raw and all the recordings were recorded with live performers and live instruments. For example, musicians more often than not record separately to a metronome, to make a recording very tight rather than being out of time with the metronome and make a performance that is not as cohesive as it could be. The consequence of this affects musicians being able to improvise which may add a different dynamic to the song. Improvisation is more likely to happen at a live event or if the musicians are recording altogether in the studio. Dynamics are effected by the person’s emotions running throughout the song whether this is a slow ballad or a fast rock song. This is in sharp contrast to MIDI where programmed drums often sounds lacklustre. This all leads onto the final section which was the recording where each musicians taking part of this changed their performance each time, this varied from tempo, improvising, speeding up and slowing down along with the timbre. The recordings compared to the computer generated songs show how music in a live setting is vastly different in dynamics, timbre, tempo along with emotion in the music. 

**References** 

Bartlett and Bartlett (2014). Recording Music on Location : Capturing the Live Performance. London : Focal Press; 1 edition (17 Jan. 2007). 60-62.

Berndt and Hähnel,(2010) [Modelling Musical Dynamics] [ Accessed 15th September 2019] Available at: < https://www.researchgate.net/publication/220958348  >.

Bell, J, (2005) [Doing your Research Project] [ Accessed 16th September 2019] Available at:<http://elearning.ufl.udn.vn/home/esp/pluginfile.php/3274/mod_resource/content/1/Judith%20Bell%20-%20Doing_Your_Research_Project.pdf >.

Bradley,N (2013). Marketing Research . oxford: Oxford University Press. 198-199.

Bresin (2000) [Emotional Coloring of Computer-Controlled Music Performances] [ Accessed 7th September 2019] Available at: <https://www.researchgate.net/publication/234819721 >.

Bresin (2008) [Computer – Generating emotional Music: The Design Of An Affective Music Algorithm] [ Accessed 9th September 2019] Available at: < https://pdfs.semanticscholar.org/9d4a/8d1876d0bc92f805248a5e7d7866a9710285.pdf?_ga=2.148190004.2490931.1568314712-277899405.1568314712 >.

Conant (2014) [A study of cognitive processes of children creating music in a computer learning environment.] [ Accessed 14th September 2019] Available at: < https://scholarworks.umass.edu/cgi/viewcontent.cgi?article=5340&=&context=dissertations_1&=&sei-redir=1&referer=https%253A%252F%252Fscholar.google.com%252Fscholar%253Fhl%253Den%2526as_sdt%253D0%25252C5%2526q%253Dadvantages%252Bof%252Bof%252Bcreating%252Bmusic%252Bon%252Ba%252Bcomputer%2526btnG%253D#search=%22advantages%20creating%20music%20computer%22>.

David (1994) [Effect of Tempo and Dynamics on the Perception of Emotion in Music ] [ Accessed 13th September 2019] Available at: < https://journals.sagepub.com/doi/pdf/10.1177/0305735697252005 >.

Denscombe, M. (2014). How To Achieve A Good Response Rate . In: Denscombe, M The Good Research Guide . 5th ed. Maidenhead: Open University Press. 22-23.

Denzin and Lincoln . (2011). Paradigmatic Controversies Contradiction, And Emerging Confluences Revisited. In: Denzin N and Lincoln, Y  The Sage Handbook Of Qualitative Research. Singapore: SAGE Publications. 120-121.

Dunkley and Houghton. (2011). Replacing & Reinforcing Recorded Drums. Available: https://www.soundonsound.com/techniques/replacing-reinforcing-recorded-drums. Last accessed 8th September.

Debarnot (2014) [When music tempo affects the temporal congruence between physical practice and motor imagery] [ Accessed 7th September 2019] Available at: < http://isiarticles.com/bundles/Article/pre/pdf/29679.pdf >.

Falk, E. (2014). Why do bands often play songs faster live than they are recorded for the album?. Available: https://www.quora.com/Why-do-bands-often-play-songs-faster-live-than-they-are-recorded-for-the-album. Last accessed 7th September 2019.

Friberg, A. (2000). Emotional Coloring of Computer-Controlled Music Performances. Available: https://kth.diva-portal.org/smash/get/diva2:1246195/FULLTEXT01.pdf. Last accessed 7th September 2019.

Geretsegger (2014) [Music therapy for people with autism spectrum disorder ] [ Accessed 14th September 2019] Available at: < https://www.cochranelibrary.com/cdsr/doi/10.1002/14651858.CD004381.pub3/epdf/full  >.

Goertz, G and Mahoney, J. (2012). Explicit and Implicit Practices . In: Goertz, G and Mahoney, J A Tale of Two Cultures: Qualitative and Quantitative Research in the Social Sciences. 9th ed. Oxford: Princeton University. 7-8.

Hersen, M. (2005). advantages and Disadvantages of structured and Semistructured intervies. In: Hersen, M Clinician's Handbook of Adult Behavioral Assessment. London: Elsevier Ltd. 124-125.

Hoepfinger, H. (2018). Bass Bench: The Pros and Cons of Pitch-to-MIDI Technologies. Available: https://www.premierguitar.com/articles/27324-bass-bench-the-pros-and-cons-of-pitch-to-midi-technologies. Last accessed 7th September.

Hracs,B Tarek,E. Virani, et al.. (2016). The Limits. In: Hracs,B Tarek,E. Virani, et al. The Production and Consumption of Music in the Digital Age. New York: Routledge. 54-55.

Horning, S (2016). Chasing Sound: Technology, Culture, and the Art of Studio Recording from Edison to the LP. New York: Johns Hopkins University Press. 50-51.

Hube, D. (2007). MIDI Guitar and Basses. In: Hube, D The MIDI Manual: A Practical Guide to MIDI in the Project Studio (Audio Engineering Society Present. 3rd ed. Berlin: Routledge. 99-100.

Huber, D and Runstein, R. (2009). Latency . In: Huber, D and Runstein, R Modern Recording Techniques. 7th ed. Oxford: Focal Press . 252-253.

Kagan, A. (2013). Analog Tape vs Digital Recording: Which sounds better?. Available: http://recordinghacks.com/2013/01/26/analog-tape-vs-digital/. Last accessed 11th September 2013.

Killelea, P. (2002). Performance monitoring. In: Killelea, P Web Performance Tuning: Speeding Up the Web. New Yorkk: O'Reilly Media. 53-54.

Lexer, S (2012) [Live Electronics in Live Performance:] [ Accessed 11th September 2019] Available at: < https://research.gold.ac.uk/8005/1/MUS_thesis_Lexer_2012.pdf  >.

Lehmann, Sloboda etall (2007). Psychology for Musicians . Oxford: Oxford University Press. 66-67.

Manaris and Brown (2014). Making Music with Computers: Creative Programming in Python. Queensland : Making Music with Computers: Creative Programming in Python. 50-51.

Menter , I (2011). A Guide to Practitioner Research in Education. California: SAGE Publications Ltd. 104-105.

Miranda, E (2001). Composing Music with Computers (Music Technology). London: Focal Press . 22-23.

Munro, D (1993). The Art of Sequencing: A Step by Step Approach. Manhattan: Alfred Music. 123-124.

Mynett, M. (2016). Drum samples overview. In: Mynett, M Metal Music Manual: Producing, Engineering, Mixing, and Mastering Contemporary Heavy Music . London: Routledge. 177-178.

Nachmanovitch, S. (1993). Introduction . In: Nachmanovitch, S Free Play: Power of Improvisation in Life and the Arts. New York: Jeremy P Tarcher. 72-72.

Nelson, D (2010). Snip, Burn, Solder, Shred: Seriously Geeky Stuff to Make with Your Kids. London: No Starch Press. 139-140.

Pack, B. (2018). How To Use Drum Samples To Make Your Drum recordings Sound better. Available: https://reverb.com/uk/news/how-to-use-drum-samples-to-make-your-drum-recordings-sound-better. Last accessed 14th September 2019.

Patton, M. (2002). Recognizing Qualitative Data. In: Patton, M Qualitative Research & Evaluation Methods. 3rd ed. Lonon: SAGE Publications. 4-5.

Pejrolo and DeRosa. (2007). Sequencing Techniques For The Bass. In: Pejrolo, A Acoustic and MIDI Orchestration for the Contemporary Composer. Boston: Focal Press . 71-72.

Punch, K (2005). Introduction to Social Research, Second Edition: Quantitative and Qualitative Approaches . 2nd ed. London: Sage Publications Ltd. 276-277.

Short, A. (2018). How Music Can Be Used To Help Autistic People.Available: https://the-art-of-autism.com/how-music-can-be-used-to-help-autistic-people/. Last accessed 14th September 2019.

Sloboda, J (2010). Handbook of Music and Emotion: Theory, Research, Applications. New York: Oxford University Press. 455-456.

Thiemel, M. (2019). Dynamics. Available: https://www.oxfordmusiconline.com/grovemusic/view/10.1093/gmo/9781561592630.001.0001/omo-9781561592630-e-0000008458. Last accessed 7th September 2019.

Try, A. (2009). How to Create Music Without Playing an Instrument.Available: https://music.tutsplus.com/articles/how-to-create-music-without-playing-an-instrument--audio-2024. Last accessed 14th September 2019.

Wessel, D. (1996). Timbre Space as a Musical Control Structure.. Timbre Space as a Musical Control Structure.. 3 (3), 45-52.

White, P . (1999). What is Midi. In: David Houghton Basic Midi. London : Sanctuary Publishing limited. 18-19.

White, P . (2010). What's the best order for recording a band?.Available: https://www.soundonsound.com/sound-advice/q-whats-best-order-recording-band. Last accessed 11th September 2019.

Williams,R. (2004). Computer Sound Synthesis in 1951: The Music of CSIRAC. Available: https://www.mitpressjournals.org/doi/pdf/10.1162/014892604322970616. Last accessed 6th September 2019

Wisdom (2013) [Mixed Methods: Integrating Quantitative and Qualitative Data Collection and Analysis While Studying Patient-Centered Medical Home Models] [ Accessed 14th September 2019] Available at: < Geretsegger (2014) [Music therapy for people with autism spectrum disorder ] [ Accessed 14th September 2019] Available at: < https://www.cochranelibrary.com/cdsr/doi/10.1002/14651858.CD004381.pub3/epdf/full  >.

Woodward, I. (2013). medium in the age of digital reproduction. The vinyl: The analogue medium in the age of digital reproduction. 1 (2), 50-51.

**Appendix**

Appendix 1

![](https://github.com/dannywallin/Masters-dissertation-/blob/master/appendix%201.png)

Appendix 2

![](https://github.com/dannywallin/Masters-dissertation-/blob/master/appendix%202.png)

Appendix 3

![](https://github.com/dannywallin/Masters-dissertation-/blob/master/appendix%203.png)

Appendix 4

![](https://github.com/dannywallin/Masters-dissertation-/blob/master/appendix%204.png)

Appendix 5

![](https://github.com/dannywallin/Masters-dissertation-/blob/master/appendix%205.png)










